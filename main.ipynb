{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from Data_PreProcess import Data_preprocess as dp\n",
    "import json\n",
    "from data_loader import DataGenerate,collate\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Generate_Anchor import Generate_Anchor\n",
    "from torchvision import models\n",
    "from Net3 import Net\n",
    "from Eval import eval as eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for thres in [0.8,0.9,0.95,0.5,0.6,0.7,0.3]:\n",
    "#r,p = eval_model(model,threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_line(anchor_nums=3, batch_size=2):\n",
    "    num1 = 128*128*batch_size*anchor_nums\n",
    "    num2 = 64*64*batch_size*anchor_nums + num1\n",
    "    num3 = 32*32*batch_size*anchor_nums + num2\n",
    "    return [[0,num1],[num1,num2],[num2,num3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_size = 864\n",
    "anchor_info = {\n",
    "    \"anchor_size_3\" : [[350, 350],[425, 425],[475, 475],[400, 300],[300, 400],[450, 350],[350, 450]],\n",
    "    \"anchor_size_1\" : [[ 20,  20],[ 30,  30],[ 45,  45],[ 70,  70],[100, 100],[100,  60],[ 60, 100]],\n",
    "    \"anchor_size_2\" : [[150, 150],[225, 225],[300, 300],[225, 150],[150, 225],[100, 200],[200, 100]],\n",
    "    \"feat_size_1\":(input_size//8,input_size//8),\n",
    "    \"feat_size_2\":(input_size//16,input_size//16),\n",
    "    \"feat_size_3\":(input_size//32,input_size//32)\n",
    "}\n",
    "#FPN 各层生成的Anchor独立，方便修改\n",
    "anchor_generator_1 = Generate_Anchor(batch_size=batch_size,stride=8, feat_size=anchor_info[\"feat_size_1\"],anchor_size=anchor_info[\"anchor_size_1\"])\n",
    "anchor_generator_2 = Generate_Anchor(batch_size=batch_size,stride=16, feat_size=anchor_info[\"feat_size_2\"],anchor_size=anchor_info[\"anchor_size_2\"])\n",
    "anchor_generator_3 = Generate_Anchor(batch_size=batch_size,stride=32, feat_size=anchor_info[\"feat_size_3\"],anchor_size=anchor_info[\"anchor_size_3\"])\n",
    "train_generate = DataLoader(DataGenerate(batch_size=batch_size, input_size=input_size), batch_size = batch_size, drop_last = True,collate_fn=collate)\n",
    "\n",
    "model = Net(input_size=864,batch_size=batch_size, anchor_info=anchor_info)\n",
    "model.load_state_dict(torch.load(r\"E:\\cancer\\model\\model_include3\\eps=3.t7\"),strict = False)\n",
    "model = model.cuda()\n",
    "#eval_model(model, input_size = input_size, thres=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor(data):\n",
    "    label_1,label_valid_1, loc_1,cls_1 = anchor_generator_1.getAnchor(data)\n",
    "    label_2,label_valid_2, loc_2,cls_2 = anchor_generator_2.getAnchor(data)\n",
    "    label_3,label_valid_3, loc_3,cls_3 = anchor_generator_3.getAnchor(data)\n",
    "    return torch.from_numpy(np.hstack([label_1,label_2,label_3])).cuda().float(),\\\n",
    "            torch.from_numpy(np.hstack([label_valid_1,label_valid_2,label_valid_3])).cuda(),\\\n",
    "            torch.from_numpy(np.vstack([loc_1,loc_2,loc_3])).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), r\"E:\\cancer\\model\\test\\eps=11.t7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 0.000050\n",
      "trainning set =  5945\n",
      "loss_loc = 0.08032 | loss_cls = 0.03924 | loss_loc_s2 = 0.05327 | loss_cls_s2 = 0.01476 \n",
      "pos_hard = 0.78936 | pos_pos = 0.52976 | hard_hard = 0.31101\n",
      "loss_loc = 0.07985 | loss_cls = 0.03505 | loss_loc_s2 = 0.05679 | loss_cls_s2 = 0.01314 \n",
      "pos_hard = 0.70845 | pos_pos = 0.51380 | hard_hard = 0.27218\n",
      "loss_loc = 0.07925 | loss_cls = 0.04256 | loss_loc_s2 = 0.05379 | loss_cls_s2 = 0.01677 \n",
      "pos_hard = 0.79037 | pos_pos = 0.53164 | hard_hard = 0.29449\n",
      "loss_loc = 0.07669 | loss_cls = 0.03411 | loss_loc_s2 = 0.05305 | loss_cls_s2 = 0.01795 \n",
      "pos_hard = 0.79472 | pos_pos = 0.54359 | hard_hard = 0.31543\n",
      "loss_loc = 0.07724 | loss_cls = 0.03254 | loss_loc_s2 = 0.05611 | loss_cls_s2 = 0.01898 \n",
      "pos_hard = 0.71887 | pos_pos = 0.54801 | hard_hard = 0.27609\n",
      "time  2805.6521322727203\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "eval() got an unexpected keyword argument 's2_threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f7edef02bcf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"time \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"E:\\cancer\\model\\test\\eps=%d.t7\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms2_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.55\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: eval() got an unexpected keyword argument 's2_threshold'"
     ]
    }
   ],
   "source": [
    "from Generate_Anchor import generate_prior_anchor,get_prior_anchor\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "eval_prior_anchor = get_prior_anchor(input_size=input_size)\n",
    "model = model.train()\n",
    "pos_num = []\n",
    "smooth = 0.05\n",
    "loss_hist_loc_s1 = []\n",
    "loss_hist_cls_s1 = []\n",
    "loss_hist_loc_s2 = []\n",
    "loss_hist_cls_s2 = []\n",
    "loss_hist_ph = []\n",
    "loss_hist_pp = []\n",
    "loss_hist_hh = []\n",
    "learning_rate=0.0001\n",
    "lr = np.ones(4)\n",
    "for eps in range(11,20):\n",
    "    start = time.time()\n",
    "    learning_rate = learning_rate*0.5\n",
    "    print(\"learning_rate = %f\"%learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for idx,data in enumerate(train_generate):\n",
    "        #cv2.waitKey(100)\n",
    "        loss_cls_s1,loss_loc_s1,loss_cls_s2,loss_loc_s2, pos_hard, pos_pos, hard_hard = model(data[0],data[1],threshold=0.5)\n",
    "        loss = loss_cls_s1*lr[1]*1.3 + loss_loc_s1*lr[0] + loss_cls_s2 * lr[3]*1.3 + loss_loc_s2 * lr[2] + (pos_hard+pos_pos+hard_hard)*0.3\n",
    "        loss_hist_loc_s1.append(loss_loc_s1.item())\n",
    "        loss_hist_cls_s1.append(loss_cls_s1.item())\n",
    "        loss_hist_loc_s2.append(loss_loc_s2.item())\n",
    "        loss_hist_cls_s2.append(loss_cls_s2.item())\n",
    "        loss_hist_ph.append(pos_hard.item())\n",
    "        loss_hist_pp.append(pos_pos.item())\n",
    "        loss_hist_hh.append(hard_hard.item())\n",
    "        if((idx%500 == 0) and idx>0):\n",
    "            loss_mean = np.array([np.mean(loss_hist_loc_s1),np.mean(loss_hist_cls_s1),np.mean(loss_hist_loc_s2),np.mean(loss_hist_cls_s2)])\n",
    "            print(\"loss_loc = %.5f | loss_cls = %.5f | loss_loc_s2 = %.5f | loss_cls_s2 = %.5f \"%(\n",
    "                loss_mean[0],loss_mean[1],loss_mean[2],loss_mean[3]))\n",
    "            print(\"pos_hard = %.5f | pos_pos = %.5f | hard_hard = %.5f\"%(np.mean(loss_hist_ph), np.mean(loss_hist_pp), np.mean(loss_hist_hh)))\n",
    "            loss_hist_loc_s1 = []\n",
    "            loss_hist_cls_s1 = []\n",
    "            loss_hist_loc_s2 = []\n",
    "            loss_hist_cls_s2 = []\n",
    "            loss_hist_ph = []\n",
    "            loss_hist_pp = []\n",
    "            loss_hist_hh = []\n",
    "\n",
    "            if (idx>1000):  # 根据各类loss的下降比例 调整学习率系数\n",
    "                dif = (last_loss - loss_mean)/last_loss\n",
    "                dif = np.exp(dif)\n",
    "                dif = np.sum(dif)/(dif + smooth)\n",
    "                lr = dif/np.mean(dif)\n",
    "                lr = np.clip(lr,0.1,10)\n",
    "\n",
    "            last_loss = loss_mean\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"time \",time.time() - start)\n",
    "    torch.save(model.state_dict(), r\"E:\\cancer\\model\\test\\eps=%d.t7\"%eps)\n",
    "    eval_model(model, input_size = input_size, s2_threshold=0.55)\n",
    "    model.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
