{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfbReader as kr\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from Data_PreProcess import Data_preprocess as dp\n",
    "import json\n",
    "from data_loader import DataGenerate,collate\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Generate_Anchor import Generate_Anchor\n",
    "from torchvision import models\n",
    "from Eval import eval_model\n",
    "from Net3 import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No0 process, time = 555.779760\n",
      "No1 process, time = 577.118582\n",
      "No2 process, time = 537.133116\n",
      "No3 process, time = 811.378129\n",
      "No4 process, time = 750.211802\n",
      "No5 process, time = 571.871576\n",
      "No6 process, time = 633.141597\n",
      "No7 process, time = 450.841552\n",
      "No8 process, time = 559.430474\n",
      "No9 process, time = 567.413714\n",
      "No10 process, time = 606.343294\n",
      "No11 process, time = 550.254420\n",
      "No12 process, time = 445.848145\n",
      "No13 process, time = 651.923406\n",
      "No14 process, time = 713.654817\n",
      "No15 process, time = 593.925253\n",
      "No16 process, time = 728.288754\n",
      "No17 process, time = 529.276242\n",
      "No18 process, time = 626.319445\n",
      "No19 process, time = 239.542349\n",
      "No20 process, time = 681.694781\n",
      "No21 process, time = 223.745318\n",
      "No22 process, time = 666.140396\n",
      "No23 process, time = 596.116082\n",
      "No24 process, time = 868.616122\n",
      "No25 process, time = 564.120954\n",
      "No26 process, time = 597.020490\n",
      "No27 process, time = 361.696363\n",
      "No28 process, time = 777.556842\n",
      "No29 process, time = 562.692153\n",
      "No30 process, time = 647.217047\n",
      "No31 process, time = 739.171709\n",
      "No32 process, time = 233.439110\n",
      "No33 process, time = 605.880062\n",
      "No34 process, time = 551.322539\n",
      "No35 process, time = 620.128974\n",
      "No36 process, time = 225.259396\n",
      "No37 process, time = 196.282247\n",
      "No38 process, time = 434.876072\n",
      "No39 process, time = 537.585350\n",
      "No40 process, time = 666.574552\n",
      "No41 process, time = 610.728963\n",
      "No42 process, time = 243.848807\n",
      "No43 process, time = 561.574177\n",
      "No44 process, time = 249.995160\n",
      "No45 process, time = 630.052377\n",
      "No46 process, time = 646.851073\n",
      "No47 process, time = 655.501088\n",
      "No48 process, time = 597.622089\n",
      "No49 process, time = 626.783681\n",
      "No50 process, time = 533.848407\n",
      "No51 process, time = 515.366231\n",
      "No52 process, time = 488.364389\n",
      "No53 process, time = 610.795139\n",
      "No54 process, time = 584.860134\n",
      "No55 process, time = 642.842407\n",
      "No56 process, time = 645.109439\n",
      "No57 process, time = 657.409164\n",
      "No58 process, time = 672.355933\n",
      "No59 process, time = 274.199561\n",
      "No60 process, time = 632.979164\n",
      "No61 process, time = 660.627729\n",
      "No62 process, time = 745.763248\n",
      "No63 process, time = 748.429342\n",
      "No64 process, time = 590.340716\n",
      "No65 process, time = 236.368905\n",
      "No66 process, time = 626.867904\n",
      "No67 process, time = 522.020939\n",
      "No68 process, time = 562.200845\n",
      "No69 process, time = 607.148889\n",
      "No70 process, time = 636.187614\n",
      "No71 process, time = 226.346238\n",
      "No72 process, time = 698.620816\n",
      "No73 process, time = 636.881547\n",
      "No74 process, time = 573.923034\n",
      "No75 process, time = 581.697720\n",
      "No76 process, time = 618.492620\n",
      "No77 process, time = 648.981741\n",
      "No78 process, time = 688.016291\n",
      "No79 process, time = 737.412362\n",
      "No80 process, time = 238.173255\n",
      "No81 process, time = 594.920181\n",
      "No82 process, time = 618.991544\n",
      "No83 process, time = 637.041974\n",
      "No84 process, time = 231.987121\n",
      "No85 process, time = 244.389645\n",
      "No86 process, time = 657.694925\n",
      "No87 process, time = 622.962512\n",
      "No88 process, time = 293.889351\n",
      "No89 process, time = 684.028213\n",
      "No90 process, time = 236.585898\n",
      "No91 process, time = 598.861229\n",
      "No92 process, time = 644.572594\n",
      "No93 process, time = 608.276438\n",
      "No94 process, time = 638.690360\n",
      "No95 process, time = 458.828413\n",
      "No96 process, time = 319.947471\n",
      "No97 process, time = 403.134905\n",
      "No98 process, time = 381.368871\n"
     ]
    }
   ],
   "source": [
    "def collate_sub(batch):\n",
    "    img = torch.from_numpy(batch[0][0].transpose(2, 0, 1)[np.newaxis,]).cuda().float()\n",
    "    return img, batch[0][1], batch[0][2]\n",
    "\n",
    "\n",
    "class SubGenerate(Dataset):\n",
    "    def __init__(self, imgpath, input_size):\n",
    "        self.imgpath = imgpath\n",
    "        self.input_size = input_size\n",
    "        self.reader = kr.reader()\n",
    "        self.reader.ReadInfo(imgpath, 20, True)\n",
    "        self.Width = self.reader.getWidth()\n",
    "        self.Height = self.reader.getHeight()\n",
    "        self.stride = int(input_size * 0.85)\n",
    "        self.index_w -= self.stride\n",
    "        self.index_h = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        length = ((self.Width - self.input_size) // self.stride + 1) * ((self.Height - self.input_size) // self.stride + 1)\n",
    "        self.Width -= self.input_size\n",
    "        self.Height -= self.input_size\n",
    "        # print(\"len = \", length)\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        self.index_w += self.stride\n",
    "        if (self.index_w + self.input_size > self.Width):\n",
    "            self.index_w = 0\n",
    "            self.index_h += self.stride\n",
    "        img = self.reader.ReadRoi(self.index_w, self.index_h, self.input_size, self.input_size, 20)\n",
    "        return img, self.index_w, self.index_h\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    return batch[0][0], batch[0][1]\n",
    "\n",
    "\n",
    "class InferGenerate(Dataset):\n",
    "    def __init__(self, data_path, input_size):\n",
    "        self.data_path = data_path\n",
    "        self.datalist = os.listdir(data_path)\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_name = self.datalist[index]\n",
    "        data_path = os.path.join(self.data_path, data_name)\n",
    "        sub_generater = DataLoader(SubGenerate(imgpath=data_path, input_size=self.input_size), \\\n",
    "                                   batch_size=1, drop_last=False, collate_fn=collate_sub)\n",
    "        return sub_generater, data_name\n",
    "\n",
    "\n",
    "data_path = r\"E:\\cancer\\test_1\"\n",
    "input_size = 864\n",
    "\n",
    "# 2阶段 预测\n",
    "model = Net(input_size=input_size, batch_size=1, is_training=False)\n",
    "model.load_state_dict(torch.load(r\"E:\\cancer\\model\\model_include3\\eps=3.t7\"), strict=False)\n",
    "#model = model.cuda()\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "infer_generate = DataLoader(InferGenerate(data_path=data_path, input_size=input_size), \\\n",
    "                            batch_size=1, drop_last=False, collate_fn=collate)\n",
    "with torch.no_grad():\n",
    "    for idx, dat in enumerate(infer_generate):\n",
    "        dat_name = dat[1]\n",
    "        js = []\n",
    "        start = time.time()\n",
    "        for img, w, h in dat[0]:\n",
    "            _, s2_res = model(img)\n",
    "            del img\n",
    "            if(s2_res.size(0) == 0):continue\n",
    "            s2_res[:, 2:4] -= s2_res[:, :2]\n",
    "            s2_res[:, 0] += w\n",
    "            s2_res[:, 1] += h\n",
    "            bboxs = s2_res.detach().cpu().numpy().astype(np.float)\n",
    "            for th in range(bboxs.shape[0]):\n",
    "                bbox = bboxs[th]\n",
    "                js.append({\"x\": bbox[0], \"y\": bbox[1], \"w\": bbox[2], \"h\": bbox[3], \"p\": bbox[4]})\n",
    "            #print(\"total time : %.5f\", time.time() - start)\n",
    "        with open(r\"D:\\ans\\%s.json\" % dat_name[:-4], 'w') as f:\n",
    "            json.dump(js, f)\n",
    "        print(\"No%d process, time = %f\" % (idx, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1阶段 预测\n",
    "# 用于 retinanet\n",
    "data_path = r\"E:\\cancer\\neg_1\"\n",
    "datalist = os.listdir(data_path)\n",
    "\n",
    "input_size = 2560\n",
    "prior_anchor = get_prior_anchor(input_size = input_size)\n",
    "with torch.no_grad():\n",
    "    for idx,dat_name in enumerate(datalist):\n",
    "        start = time.time()\n",
    "        reader = kr.reader()\n",
    "        reader.ReadInfo(os.path.join(data_path, dat_name),20,True)\n",
    "        width = reader.getWidth() - input_size\n",
    "        height = reader.getHeight() - input_size\n",
    "        js = []\n",
    "        for h in range(0,height,input_size):  #后续改成 d = self.input_size/2 \n",
    "            for w in range(0,width,input_size):\n",
    "                #cv2.waitKey(100)\n",
    "                img = reader.ReadRoi(w,h,input_size,input_size,20)\n",
    "                img = img.transpose(2,0,1)[np.newaxis,]\n",
    "                img = torch.from_numpy(img).cuda().float()\n",
    "                pred_cls,pred_loc = model(img)\n",
    "                index = pred_cls>0.9\n",
    "                if (torch.sum(index) > 0) and (torch.sum(index) < 2000):\n",
    "                    scores = pred_cls[index]\n",
    "                    pred_loc = pred_loc[index]\n",
    "                    src_anchor = prior_anchor[index]\n",
    "                    x = pred_loc[:,0] * src_anchor[:,2] + src_anchor[:,0] + w\n",
    "                    y = pred_loc[:,1] * src_anchor[:,3] + src_anchor[:,1] + h\n",
    "                    _w = torch.exp(pred_loc[:,2]) * src_anchor[:,2]\n",
    "                    _h = torch.exp(pred_loc[:,3]) * src_anchor[:,3]\n",
    "                    pred = torch.stack((x,y,_w,_h,scores),axis=1).detach().cpu().numpy()\n",
    "                    pred = np.clip(pred,0,None)\n",
    "                    pred[:,2:4] += pred[:,:2]\n",
    "                    index = dp.py_cpu_nms(pred)\n",
    "                    bboxs = pred[index].astype(np.float)\n",
    "                    bboxs[:,2:4] -= bboxs[:,:2]\n",
    "                    for th in range(bboxs.shape[0]):\n",
    "                        bbox = bboxs[th]\n",
    "                        js.append({\"x\":bbox[0], \"y\":bbox[1], \"w\":bbox[2], \"h\":bbox[3], \"p\":bbox[4]})\n",
    "        with open(r\"E:\\cancer\\neg_label\\neg_label_1\\%s.json\"%dat_name[:-4],'w') as f:\n",
    "            json.dump(js,f)\n",
    "        print(\"No%d process, time = %.3f\"%(idx, time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
